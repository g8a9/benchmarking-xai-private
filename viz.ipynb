{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "amber-lincoln",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "owned-spirit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_metric, Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from einops import rearrange\n",
    "from helper import VizHelper\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from custom_bert import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "seasonal-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-smoke",
   "metadata": {},
   "source": [
    "# AMI18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "normal-spanking",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"./bert-base-cased_ami18/\"\n",
    "tokenizer_name = \"bert-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "composed-sister",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "def preprocess_text(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "quantitative-commons",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d451d72b02504e9b869caf75380375dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413cc3c54e89497aa67beab4a130c6f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca0e8fa2de1b44b48e41e27ab8c9ab60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/miso_train.tsv\", sep=\"\\t\")\n",
    "validation = pd.read_csv(\"data/miso_dev.tsv\", sep=\"\\t\")\n",
    "test = pd.read_csv(\"data/miso_test.tsv\", sep=\"\\t\")\n",
    "\n",
    "raw_datasets = DatasetDict(\n",
    "    train=Dataset.from_pandas(train),\n",
    "    validation=Dataset.from_pandas(validation),\n",
    "    test=Dataset.from_pandas(test)\n",
    ")\n",
    "raw_datasets = raw_datasets.rename_column(\"misogynous\", \"label\")\n",
    "proc_datasets = raw_datasets.map(preprocess_text, batched=True, remove_columns=raw_datasets[\"train\"].features)\n",
    "proc_datasets.set_format(\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "signal-diagnosis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Calling custom BertForSequenceClassification ***\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name).eval()\n",
    "effective_model = BertForSequenceClassification.from_pretrained(model_name).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "blond-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = VizHelper(model, tokenizer, raw_datasets[\"test\"], proc_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-hughes",
   "metadata": {},
   "source": [
    "Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_attention(idx=21, head=3, layer=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_effective_attention(idx=21, head=3, layer=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, head, layer = 21, 7, 2\n",
    "fig = exp.compare_attentions(idx, head, layer)\n",
    "fig.savefig(f\"plots/comp_attentions_{idx}_{head}_{layer}.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-component",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, head, layer = 21, 1, 9\n",
    "fig = exp.compare_attentions(idx, head, layer)\n",
    "fig.savefig(f\"plots/comp_attentions_{idx}_{head}_{layer}.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-drunk",
   "metadata": {},
   "source": [
    "Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.classify(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-northeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = exp.compute_table(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_excel(\"table.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, head, layer = 21, 1, 2\n",
    "fig = exp.compare_attentions(idx, head, layer, effective_model=effective_model, fontsize=18)\n",
    "fig.savefig(f\"plots/comp_attentions_{idx}_{head}_{layer}.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-activation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad, embeds = exp.get_gradient(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-clock",
   "metadata": {},
   "source": [
    "Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-mother",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.get_gradient(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-standing",
   "metadata": {},
   "source": [
    "Final table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = exp.compute_table(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-helicopter",
   "metadata": {},
   "source": [
    "SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sunset-campus",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Kernel Shap attribution:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:   2%|▎         | 5/200 [00:00<00:20,  9.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:   5%|▌         | 10/200 [00:01<00:20,  9.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:   8%|▊         | 15/200 [00:01<00:20,  9.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  10%|█         | 20/200 [00:02<00:20,  8.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  12%|█▎        | 25/200 [00:02<00:19,  9.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  15%|█▌        | 30/200 [00:03<00:19,  8.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  18%|█▊        | 35/200 [00:03<00:18,  9.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  20%|██        | 40/200 [00:04<00:17,  9.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  22%|██▎       | 45/200 [00:04<00:16,  9.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  25%|██▌       | 50/200 [00:05<00:15,  9.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  28%|██▊       | 55/200 [00:05<00:15,  9.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  30%|███       | 60/200 [00:06<00:15,  9.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  32%|███▎      | 65/200 [00:07<00:14,  9.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  35%|███▌      | 70/200 [00:07<00:13,  9.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  38%|███▊      | 75/200 [00:08<00:13,  9.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  40%|████      | 80/200 [00:08<00:12,  9.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  42%|████▎     | 85/200 [00:09<00:12,  9.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  45%|████▌     | 90/200 [00:09<00:11,  9.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  48%|████▊     | 95/200 [00:10<00:11,  9.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  50%|█████     | 100/200 [00:10<00:10,  9.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  52%|█████▎    | 105/200 [00:11<00:09,  9.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  55%|█████▌    | 110/200 [00:11<00:09,  9.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  57%|█████▊    | 115/200 [00:12<00:09,  9.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  60%|██████    | 120/200 [00:12<00:08,  9.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  62%|██████▎   | 125/200 [00:13<00:08,  9.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  65%|██████▌   | 130/200 [00:13<00:07,  9.41it/s]\u001b[A\u001b[A\n",
      "Kernel Shap attribution:  38%|███▊      | 75/200 [00:27<00:13,  9.26it/s]\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  68%|██████▊   | 135/200 [00:14<00:06,  9.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  70%|███████   | 140/200 [00:15<00:06,  9.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  72%|███████▎  | 145/200 [00:15<00:05,  9.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  75%|███████▌  | 150/200 [00:16<00:05,  9.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  78%|███████▊  | 155/200 [00:16<00:04,  9.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  80%|████████  | 160/200 [00:17<00:04,  9.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  82%|████████▎ | 165/200 [00:17<00:03,  9.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  85%|████████▌ | 170/200 [00:18<00:03,  9.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  88%|████████▊ | 175/200 [00:18<00:02,  9.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  90%|█████████ | 180/200 [00:19<00:02,  9.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  92%|█████████▎| 185/200 [00:19<00:01,  9.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  95%|█████████▌| 190/200 [00:20<00:01,  9.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution:  98%|█████████▊| 195/200 [00:20<00:00,  9.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "Kernel Shap attribution: 100%|██████████| 200/200 [00:21<00:00,  9.36it/s]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "shap = exp.get_kernel_shap(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "rural-cause",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap[0, :, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "hearing-elder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298, 0.0298,\n",
       "        0.0298, 0.0298, 0.0298])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap[0, 120, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unbias_venv",
   "language": "python",
   "name": "unbias_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
